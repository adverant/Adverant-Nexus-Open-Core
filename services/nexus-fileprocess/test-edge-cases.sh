#!/bin/bash

################################################################################
# FileProcessAgent Edge Case Testing Suite
################################################################################
#
# Tests unknown file types, corrupted files, edge cases, and error handling
# to ensure robust production behavior.
#
# Test Categories:
# 1. Unknown/Unsupported File Types (.bin, .xyz, .unknown, executable)
# 2. Complex Document Formats (encrypted PDF, password-protected, corrupted)
# 3. Edge Cases (empty files, massive files, special characters, Unicode)
# 4. Concurrent Processing & Queue Management
# 5. Error Handling & Recovery
#
# Usage:
#   ./test-edge-cases.sh                  # Run all tests
#   ./test-edge-cases.sh --category 1     # Run specific category
#   ./test-edge-cases.sh --quick          # Run quick smoke tests only
#
################################################################################

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
API_URL="${API_URL:-http://localhost:9099}"
API_BASE_PATH="${API_BASE_PATH:-/fileprocess/api}"
USER_ID="${USER_ID:-edge-case-tester}"
TEST_DIR="/tmp/fileprocess-edge-case-tests-$$"
RESULTS_FILE="${TEST_DIR}/test-results.json"
VERBOSE="${VERBOSE:-false}"

# Test counters
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0
SKIPPED_TESTS=0

# Test mode
CATEGORY="${1:-all}"
QUICK_MODE=false

################################################################################
# Helper Functions
################################################################################

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[PASS]${NC} $1"
}

log_error() {
    echo -e "${RED}[FAIL]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_test() {
    echo -e "${MAGENTA}[TEST]${NC} $1"
}

log_skip() {
    echo -e "${CYAN}[SKIP]${NC} $1"
}

# Initialize test environment
init_test_env() {
    log_info "Initializing test environment..."

    # Create test directory
    mkdir -p "${TEST_DIR}"

    # Initialize results file
    echo '{"tests": [], "summary": {}}' > "${RESULTS_FILE}"

    log_success "Test environment ready: ${TEST_DIR}"
}

# Cleanup test environment
cleanup_test_env() {
    log_info "Cleaning up test environment..."

    if [ -d "${TEST_DIR}" ]; then
        rm -rf "${TEST_DIR}"
        log_success "Cleanup complete"
    fi
}

# Check if API is available
check_api_health() {
    log_info "Checking API health..."

    if ! curl -s -f "${API_URL}/health" > /dev/null 2>&1; then
        log_error "FileProcessAgent API is not available at ${API_URL}"
        log_error "Please start the service first: docker-compose up -d nexus-fileprocess-api"
        exit 1
    fi

    log_success "API is healthy"
}

# Submit file for processing
submit_file() {
    local filepath="$1"
    local expected_result="${2:-success}" # success, failure, timeout
    local metadata="${3:-{}}"

    local filename=$(basename "${filepath}")

    TOTAL_TESTS=$((TOTAL_TESTS + 1))

    log_test "Submitting: ${filename} (expecting: ${expected_result})"

    # Submit file
    local response=$(curl -s -w "\n%{http_code}" -X POST "${API_URL}${API_BASE_PATH}/process" \
        -F "file=@${filepath}" \
        -F "userId=${USER_ID}" \
        -F "metadata=${metadata}")

    local http_code=$(echo "${response}" | tail -n 1)
    local body=$(echo "${response}" | head -n -1)

    if [ "${VERBOSE}" = "true" ]; then
        echo "HTTP Code: ${http_code}"
        echo "Response: ${body}"
    fi

    # Check HTTP status
    if [ "${expected_result}" = "failure" ]; then
        # We expect an error (4xx or 5xx)
        if [ "${http_code}" -ge 400 ]; then
            log_success "Correctly rejected: ${filename} (HTTP ${http_code})"
            PASSED_TESTS=$((PASSED_TESTS + 1))
            return 0
        else
            log_error "Expected failure but got HTTP ${http_code}: ${filename}"
            FAILED_TESTS=$((FAILED_TESTS + 1))
            return 1
        fi
    fi

    # For success cases, check if we got a job ID
    if [ "${http_code}" -eq 202 ] || [ "${http_code}" -eq 200 ]; then
        local job_id=$(echo "${body}" | jq -r '.jobId // empty')

        if [ -z "${job_id}" ]; then
            log_error "No job ID returned: ${filename}"
            FAILED_TESTS=$((FAILED_TESTS + 1))
            return 1
        fi

        log_success "Job submitted: ${job_id}"

        # Wait for job to complete (with timeout)
        wait_for_job "${job_id}" "${filename}" "${expected_result}"

    else
        log_error "Unexpected HTTP code ${http_code}: ${filename}"
        FAILED_TESTS=$((FAILED_TESTS + 1))
        return 1
    fi
}

# Wait for job completion
wait_for_job() {
    local job_id="$1"
    local filename="$2"
    local expected_result="$3"
    local max_wait=120 # 2 minutes
    local elapsed=0

    log_info "Waiting for job ${job_id} to complete..."

    while [ ${elapsed} -lt ${max_wait} ]; do
        sleep 2
        elapsed=$((elapsed + 2))

        local job_status=$(curl -s "${API_URL}${API_BASE_PATH}/jobs/${job_id}")
        local status=$(echo "${job_status}" | jq -r '.job.status // empty')

        if [ "${VERBOSE}" = "true" ]; then
            echo "Status after ${elapsed}s: ${status}"
        fi

        case "${status}" in
            "completed")
                log_success "Job completed: ${filename}"
                PASSED_TESTS=$((PASSED_TESTS + 1))
                return 0
                ;;
            "failed")
                if [ "${expected_result}" = "failure" ]; then
                    log_success "Job correctly failed: ${filename}"
                    PASSED_TESTS=$((PASSED_TESTS + 1))
                else
                    local error=$(echo "${job_status}" | jq -r '.job.error // "unknown error"')
                    log_error "Job failed: ${filename} - ${error}"
                    FAILED_TESTS=$((FAILED_TESTS + 1))
                fi
                return 0
                ;;
            "processing"|"waiting"|"active")
                # Still processing
                continue
                ;;
            *)
                log_warning "Unknown status: ${status}"
                continue
                ;;
        esac
    done

    # Timeout
    log_error "Job timeout after ${max_wait}s: ${filename}"
    FAILED_TESTS=$((FAILED_TESTS + 1))
    return 1
}

################################################################################
# Test Category 1: Unknown/Unsupported File Types
################################################################################

test_unknown_file_types() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Test Category 1: Unknown/Unsupported File Types"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    # Test 1.1: Binary executable file
    log_test "1.1: Binary executable file (.bin)"
    local bin_file="${TEST_DIR}/test.bin"
    dd if=/dev/urandom of="${bin_file}" bs=1024 count=10 2>/dev/null
    submit_file "${bin_file}" "failure" '{"test":"binary-executable"}'

    # Test 1.2: Unknown extension
    log_test "1.2: Unknown file extension (.xyz)"
    local xyz_file="${TEST_DIR}/test.xyz"
    echo "This is a file with unknown extension" > "${xyz_file}"
    submit_file "${xyz_file}" "failure" '{"test":"unknown-extension"}'

    # Test 1.3: No extension
    log_test "1.3: File with no extension"
    local no_ext_file="${TEST_DIR}/noextension"
    echo "File with no extension" > "${no_ext_file}"
    submit_file "${no_ext_file}" "failure" '{"test":"no-extension"}'

    # Test 1.4: Disguised file (binary with .txt extension)
    log_test "1.4: Disguised file (binary data with .txt extension)"
    local disguised_file="${TEST_DIR}/disguised.txt"
    dd if=/dev/urandom of="${disguised_file}" bs=1024 count=5 2>/dev/null
    submit_file "${disguised_file}" "failure" '{"test":"disguised-binary"}'

    # Test 1.5: Shell script
    log_test "1.5: Shell script file (.sh)"
    local sh_file="${TEST_DIR}/script.sh"
    echo '#!/bin/bash\necho "Hello World"' > "${sh_file}"
    chmod +x "${sh_file}"
    submit_file "${sh_file}" "failure" '{"test":"shell-script"}'

    # Test 1.6: Python script
    log_test "1.6: Python script file (.py)"
    local py_file="${TEST_DIR}/script.py"
    echo 'print("Hello World")' > "${py_file}"
    submit_file "${py_file}" "failure" '{"test":"python-script"}'
}

################################################################################
# Test Category 2: Complex Document Formats
################################################################################

test_complex_documents() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Test Category 2: Complex Document Formats"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    # Test 2.1: Empty PDF
    log_test "2.1: Empty PDF file"
    local empty_pdf="${TEST_DIR}/empty.pdf"
    # Create minimal PDF
    cat > "${empty_pdf}" << 'EOF'
%PDF-1.4
1 0 obj
<< /Type /Catalog /Pages 2 0 R >>
endobj
2 0 obj
<< /Type /Pages /Count 0 /Kids [] >>
endobj
xref
0 3
0000000000 65535 f
0000000009 00000 n
0000000058 00000 n
trailer
<< /Size 3 /Root 1 0 R >>
startxref
109
%%EOF
EOF
    submit_file "${empty_pdf}" "success" '{"test":"empty-pdf"}'

    # Test 2.2: Corrupted PDF (truncated)
    log_test "2.2: Corrupted PDF (truncated)"
    local corrupt_pdf="${TEST_DIR}/corrupt.pdf"
    echo "%PDF-1.4" > "${corrupt_pdf}"
    echo "This is not a valid PDF" >> "${corrupt_pdf}"
    submit_file "${corrupt_pdf}" "failure" '{"test":"corrupted-pdf"}'

    # Test 2.3: PDF with special characters in content
    log_test "2.3: PDF with special characters"
    local special_pdf="${TEST_DIR}/special.pdf"
    # Create a simple text file first
    echo "Special chars: Ã©Ã±Ã¼â„¢Â®Â©ğŸš€ğŸ’¯" > "${TEST_DIR}/special.txt"
    # Note: In real scenario, we'd use a PDF library to create this
    # For now, we'll submit the text file
    submit_file "${TEST_DIR}/special.txt" "success" '{"test":"special-chars"}'

    # Test 2.4: Very large file (simulated)
    if [ "${QUICK_MODE}" = "false" ]; then
        log_test "2.4: Large file (10MB)"
        local large_file="${TEST_DIR}/large.txt"
        dd if=/dev/zero of="${large_file}" bs=1M count=10 2>/dev/null
        submit_file "${large_file}" "success" '{"test":"large-file"}'
    else
        log_skip "2.4: Large file test (use --full to enable)"
        SKIPPED_TESTS=$((SKIPPED_TESTS + 1))
    fi

    # Test 2.5: File with BOM (Byte Order Mark)
    log_test "2.5: File with UTF-8 BOM"
    local bom_file="${TEST_DIR}/bom.txt"
    printf '\xEF\xBB\xBFHello World' > "${bom_file}"
    submit_file "${bom_file}" "success" '{"test":"utf8-bom"}'
}

################################################################################
# Test Category 3: Edge Cases
################################################################################

test_edge_cases() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Test Category 3: Edge Cases"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    # Test 3.1: Truly empty file (0 bytes)
    log_test "3.1: Empty file (0 bytes)"
    local empty_file="${TEST_DIR}/empty.txt"
    touch "${empty_file}"
    submit_file "${empty_file}" "failure" '{"test":"zero-bytes"}'

    # Test 3.2: File with only whitespace
    log_test "3.2: File with only whitespace"
    local whitespace_file="${TEST_DIR}/whitespace.txt"
    printf '   \n\t\n   ' > "${whitespace_file}"
    submit_file "${whitespace_file}" "success" '{"test":"whitespace-only"}'

    # Test 3.3: Unicode filename
    log_test "3.3: Unicode filename (ä¸­æ–‡.txt)"
    local unicode_file="${TEST_DIR}/ä¸­æ–‡.txt"
    echo "Unicode content: ä½ å¥½ä¸–ç•Œ" > "${unicode_file}"
    submit_file "${unicode_file}" "success" '{"test":"unicode-filename"}'

    # Test 3.4: Filename with spaces and special chars
    log_test "3.4: Filename with spaces and special chars"
    local special_name="${TEST_DIR}/test file (2024) [v1].txt"
    echo "Content" > "${special_name}"
    submit_file "${special_name}" "success" '{"test":"special-filename"}'

    # Test 3.5: Very long filename
    log_test "3.5: Very long filename (200 chars)"
    local long_name="${TEST_DIR}/$(printf 'a%.0s' {1..200}).txt"
    echo "Content" > "${long_name}"
    submit_file "${long_name}" "success" '{"test":"long-filename"}'

    # Test 3.6: Single character file
    log_test "3.6: Single character file"
    local single_char="${TEST_DIR}/single.txt"
    echo "a" > "${single_char}"
    submit_file "${single_char}" "success" '{"test":"single-char"}'

    # Test 3.7: File with only newlines
    log_test "3.7: File with only newlines"
    local newlines_file="${TEST_DIR}/newlines.txt"
    printf '\n\n\n\n\n' > "${newlines_file}"
    submit_file "${newlines_file}" "success" '{"test":"newlines-only"}'
}

################################################################################
# Test Category 4: Concurrent Processing
################################################################################

test_concurrent_processing() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Test Category 4: Concurrent Processing & Queue Management"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    if [ "${QUICK_MODE}" = "true" ]; then
        log_skip "4.1-4.3: Concurrent processing tests (use --full to enable)"
        SKIPPED_TESTS=$((SKIPPED_TESTS + 3))
        return
    fi

    # Test 4.1: Submit 10 files simultaneously
    log_test "4.1: Submit 10 files concurrently"
    local pids=()
    for i in {1..10}; do
        local concurrent_file="${TEST_DIR}/concurrent_${i}.txt"
        echo "File ${i} content" > "${concurrent_file}"
        submit_file "${concurrent_file}" "success" "{\"test\":\"concurrent\",\"index\":${i}}" &
        pids+=($!)
    done

    # Wait for all background jobs
    for pid in "${pids[@]}"; do
        wait ${pid}
    done

    log_success "Concurrent submission test complete"

    # Test 4.2: Check queue statistics
    log_test "4.2: Check queue statistics"
    local queue_stats=$(curl -s "${API_URL}${API_BASE_PATH}/queue/stats")
    local waiting=$(echo "${queue_stats}" | jq -r '.stats.waiting // 0')
    local active=$(echo "${queue_stats}" | jq -r '.stats.active // 0')

    log_info "Queue stats: ${waiting} waiting, ${active} active"
    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    PASSED_TESTS=$((PASSED_TESTS + 1))

    # Test 4.3: List recent jobs
    log_test "4.3: List recent jobs"
    local jobs_list=$(curl -s "${API_URL}${API_BASE_PATH}/jobs?state=completed&start=0&end=5")
    local job_count=$(echo "${jobs_list}" | jq '.jobs | length')

    log_info "Found ${job_count} recent completed jobs"
    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    PASSED_TESTS=$((PASSED_TESTS + 1))
}

################################################################################
# Test Category 5: Error Handling & Recovery
################################################################################

test_error_handling() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Test Category 5: Error Handling & Recovery"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    # Test 5.1: Missing file parameter
    log_test "5.1: Missing file parameter"
    local response=$(curl -s -w "\n%{http_code}" -X POST "${API_URL}${API_BASE_PATH}/process" \
        -F "userId=${USER_ID}")
    local http_code=$(echo "${response}" | tail -n 1)

    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    if [ "${http_code}" -ge 400 ]; then
        log_success "Correctly rejected missing file (HTTP ${http_code})"
        PASSED_TESTS=$((PASSED_TESTS + 1))
    else
        log_error "Expected error but got HTTP ${http_code}"
        FAILED_TESTS=$((FAILED_TESTS + 1))
    fi

    # Test 5.2: Invalid job ID query
    log_test "5.2: Query non-existent job ID"
    local invalid_job="00000000-0000-0000-0000-000000000000"
    local response=$(curl -s -w "\n%{http_code}" "${API_URL}${API_BASE_PATH}/jobs/${invalid_job}")
    local http_code=$(echo "${response}" | tail -n 1)

    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    if [ "${http_code}" -eq 404 ]; then
        log_success "Correctly returned 404 for invalid job"
        PASSED_TESTS=$((PASSED_TESTS + 1))
    else
        log_warning "Expected 404 but got HTTP ${http_code}"
        PASSED_TESTS=$((PASSED_TESTS + 1)) # Still pass, just not ideal
    fi

    # Test 5.3: Malformed metadata JSON
    log_test "5.3: Malformed metadata JSON"
    local test_file="${TEST_DIR}/metadata_test.txt"
    echo "Test content" > "${test_file}"
    local response=$(curl -s -w "\n%{http_code}" -X POST "${API_URL}${API_BASE_PATH}/process" \
        -F "file=@${test_file}" \
        -F "userId=${USER_ID}" \
        -F 'metadata={invalid json}')
    local http_code=$(echo "${response}" | tail -n 1)

    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    if [ "${http_code}" -ge 400 ]; then
        log_success "Correctly rejected malformed metadata (HTTP ${http_code})"
        PASSED_TESTS=$((PASSED_TESTS + 1))
    else
        log_warning "Expected error but got HTTP ${http_code} (may have been sanitized)"
        PASSED_TESTS=$((PASSED_TESTS + 1))
    fi
}

################################################################################
# Main Test Runner
################################################################################

run_tests() {
    local category="$1"

    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "         FileProcessAgent Edge Case Testing Suite"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""

    init_test_env
    check_api_health

    case "${category}" in
        "1"|"unknown")
            test_unknown_file_types
            ;;
        "2"|"complex")
            test_complex_documents
            ;;
        "3"|"edge")
            test_edge_cases
            ;;
        "4"|"concurrent")
            test_concurrent_processing
            ;;
        "5"|"error")
            test_error_handling
            ;;
        "all")
            test_unknown_file_types
            test_complex_documents
            test_edge_cases
            test_concurrent_processing
            test_error_handling
            ;;
        *)
            log_error "Unknown category: ${category}"
            exit 1
            ;;
    esac

    # Print summary
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "                      Test Summary"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${BLUE}Total Tests:${NC}   ${TOTAL_TESTS}"
    echo -e "${GREEN}Passed:${NC}        ${PASSED_TESTS}"
    echo -e "${RED}Failed:${NC}        ${FAILED_TESTS}"
    echo -e "${CYAN}Skipped:${NC}       ${SKIPPED_TESTS}"
    echo ""

    local success_rate=0
    if [ ${TOTAL_TESTS} -gt 0 ]; then
        success_rate=$((PASSED_TESTS * 100 / TOTAL_TESTS))
    fi
    echo -e "${BLUE}Success Rate:${NC}  ${success_rate}%"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""

    # Exit code based on results
    if [ ${FAILED_TESTS} -eq 0 ]; then
        log_success "All tests passed! âœ…"
        cleanup_test_env
        exit 0
    else
        log_error "Some tests failed. Check logs for details."
        log_info "Test directory preserved: ${TEST_DIR}"
        exit 1
    fi
}

################################################################################
# Script Entry Point
################################################################################

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --quick)
            QUICK_MODE=true
            shift
            ;;
        --full)
            QUICK_MODE=false
            shift
            ;;
        --category)
            CATEGORY="$2"
            shift 2
            ;;
        --verbose|-v)
            VERBOSE=true
            shift
            ;;
        --help|-h)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --quick           Run quick tests only (skip large files, concurrency)"
            echo "  --full            Run full test suite (default)"
            echo "  --category N      Run specific test category (1-5 or all)"
            echo "  --verbose, -v     Verbose output"
            echo "  --help, -h        Show this help message"
            echo ""
            echo "Categories:"
            echo "  1, unknown        Unknown/unsupported file types"
            echo "  2, complex        Complex document formats"
            echo "  3, edge           Edge cases (empty, Unicode, special chars)"
            echo "  4, concurrent     Concurrent processing & queue management"
            echo "  5, error          Error handling & recovery"
            echo "  all               Run all categories (default)"
            exit 0
            ;;
        *)
            CATEGORY="$1"
            shift
            ;;
    esac
done

# Trap cleanup on exit
trap cleanup_test_env EXIT

# Run tests
run_tests "${CATEGORY}"
